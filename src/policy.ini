[common]
# Use absolute time or sequence number as request time
# time_format:absolute
time_format:seq_num
statistic_window:1000000
# The testing trace length
early_stop:6000000
uni_size:false
logdir:./log
logname:{trace}_{policy}_{capacity}_{tag}.log
runtime_log:false


[belady]


[beladysize]
sample_size:-1
furthest_size:640


[lru]
sample_size:-1

[gdsf]
sample_size:64
gds_flag:true

[lrb]
sample_size:64
batch_size:131072
#batch_size:5000000
memory_window:5000000
max_n_past_timestamps:32
num_iterations:100
# Use linear for OHR goal and identity for BHR goal
# priority_size_function:linear
priority_size_function:identity
use_size:true
use_edc:false
use_n_within:true
use_seq_for_retrain:true
use_noforget:false


[ravenl]
savedir:./ckpoints/{trace}_{tag}
savename:model{window_index}
cuda:1
sample_size:64
#batch_size:1000000
batch_size:5000000
memory_window:5000000
max_n_past_timestamps:200
learn_objective:residual
train_data_type:all
consider_survival:true
use_pseudo_sample:false
consider_objid:false
consider_objsize:false
rank_criteria:sample
freq_for_gbm:10
min_n_past_distances:5
priority_size_function:identity
use_size:false
use_edc:false
use_n_within:false
dist_sample_size:100
history_type:lrb
load_ml:true
# Size of the RNN hidden vector. 32 or 64.
context_size:32
# RNN cell to use (['RNN', 'GRU', 'LSTM'])
rnn_type:GRU
ml_batch_size:256
# reload ml model before every train
reload:false
# warmup_policy:lru, ravenh
# admission_policy:priority_admission
# admission_policy:adaptsize_admission


[ravenltao]


[ravenh]
use_seq_for_retrain:true
use_noforget:true
# warmup_policy:lru, ravenh
warmup_policy:lru
# dist_sample_count:10
dist_sample_count:100
# rank_metric:sample, mean, median
rank_metric:sample
# max_lookback approximately 100 * dist_sample_count
# max_lookback:1024
max_lookback:10240
#batch_size:131072
batch_size:5000000
memory_window:1000000
# delay false is good for twitter and delay true is good for wiki
consider_decay:false
